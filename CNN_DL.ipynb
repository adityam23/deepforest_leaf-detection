{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 20:20:54.375957: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 20:20:55.065071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 20:20:55.664320: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 20:20:55.699899: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 20:20:55.700115: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, RandomContrast, RandomFlip, RandomRotation, RandomBrightness, RandomTranslation\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main data dir\n",
    "train_data_dir = Path('train/').with_suffix('')\n",
    "test_data_dir = Path('test/').with_suffix('')\n",
    "\n",
    "# Parameters\n",
    "batch_size = 32\n",
    "image_size = (150, 150)\n",
    "num_classes = 15\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acer', 'Alnus incana', 'Betula pubescens', 'Fagus silvatica', 'Populus', 'Populus tremula', 'Quercus', \"Salix alba 'Sericea'\", 'Salix aurita', 'Salix sinerea', 'Sorbus aucuparia', 'Sorbus intermedia', 'Tilia', 'Ulmus carpinifolia', 'Ulmus glabra']\n"
     ]
    }
   ],
   "source": [
    "plant_labels = [\n",
    "    \"Ulmus carpinifolia\",\n",
    "    \"Acer\",\n",
    "    \"Salix aurita\",\n",
    "    \"Quercus\",\n",
    "    \"Alnus incana\",\n",
    "    \"Betula pubescens\",\n",
    "    \"Salix alba 'Sericea'\",\n",
    "    \"Populus tremula\",\n",
    "    \"Ulmus glabra\",\n",
    "    \"Sorbus aucuparia\",\n",
    "    \"Salix sinerea\",\n",
    "    \"Populus\",\n",
    "    \"Tilia\",\n",
    "    \"Sorbus intermedia\",\n",
    "    \"Fagus silvatica\"\n",
    "]\n",
    "plant_labels = sorted(plant_labels)\n",
    "print(plant_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 720 images belonging to 15 classes.\n",
      "Found 180 images belonging to 15 classes.\n",
      "Found 225 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data loading and preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # rescale data\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2\n",
    ")  # 20% validation split\n",
    "\n",
    "# Load and preprocess data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=42\n",
    "    )\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    seed=42\n",
    "    )\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map_train = {v: k for k, v in train_generator.class_indices.items()}\n",
    "inv_map_test = {v: k for k, v in test_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 20:20:56.317219: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 20:20:56.317610: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 20:20:56.317896: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 20:20:56.383990: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 20:20:56.384207: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 20:20:56.384379: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-30 20:20:56.384516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4277 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Augment Data\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  RandomRotation(0.3),\n",
    "  RandomContrast(0.3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model creation\n",
    "def create_model(hp):\n",
    "    # Units for dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(data_augmentation)\n",
    "    # Number of layers for the CNN\n",
    "    for i in range(1, hp.Int(\"num_layers\", 2, 6)):\n",
    "        # Number of filters in Conv2D layers\n",
    "        model.add(Conv2D(hp.Int(f\"filters_{i}\", 32, 128, step=32), (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=hp_units, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Learning rates\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from runs/leaf_class/tuner0.json\n",
      "Reloading Tuner from runs_bo/leaf_class/tuner0.json\n",
      "Reloading Tuner from runs_rs/leaf_class/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "                     create_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=epochs,\n",
    "                     factor=3,\n",
    "                     directory='runs',\n",
    "                     project_name='leaf_class'\n",
    "                    )\n",
    "\n",
    "tuner_bo = kt.BayesianOptimization(\n",
    "                     create_model,\n",
    "                     objective='val_loss',\n",
    "                     directory='runs_bo',\n",
    "                     project_name='leaf_class'\n",
    "                    )\n",
    "\n",
    "tuner_rs = kt.RandomSearch(\n",
    "                     create_model,\n",
    "                     objective='val_loss',\n",
    "                     directory='runs_rs',\n",
    "                     project_name='leaf_class'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.search(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_bo.search(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of layers is 4. The optimal number of units in the densely-connected\n",
      "layer is 512 and the optimal learning rate for the optimizer is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search using Hyperband tuner is complete. The optimal number of layers is {best_hps.get('num_layers')}. The optimal number of units in the densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of layers is 3. The optimal number of units in the densely-connected\n",
      "layer is 224 and the optimal learning rate for the optimizer is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hps_rs=tuner_rs.get_best_hyperparameters()[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search using Random Search tuner is complete. The optimal number of layers is {best_hps_rs.get('num_layers')}. The optimal number of units in the densely-connected\n",
    "layer is {best_hps_rs.get('units')} and the optimal learning rate for the optimizer is {best_hps_rs.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of layers is 6. The optimal number of units in the densely-connected\n",
      "layer is 192 and the optimal learning rate for the optimizer is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hps_bo=tuner_bo.get_best_hyperparameters()[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search using Bayesian Optimization tuner is complete. The optimal number of layers is {best_hps_bo.get('num_layers')}. The optimal number of units in the densely-connected\n",
    "layer is {best_hps_bo.get('units')} and the optimal learning rate for the optimizer is {best_hps_bo.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucypher/Desktop/forestry/.venv/lib64/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "# model.save('hypermodel_1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rs = tuner_rs.hypermodel.build(best_hps_rs)\n",
    "# model_rs.save('hypermodel_2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bo = tuner_bo.hypermodel.build(best_hps_bo)\n",
    "# model_bo.save('hypermodel_3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('hypermodel_1.keras')\n",
    "# model_rs = tf.keras.models.load_model('hypermodel_2.keras')\n",
    "# model_bo = tf.keras.models.load_model('hypermodel_3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucypher/Desktop/forestry/.venv/lib64/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2024-04-30 20:21:00.482164: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 268ms/step - accuracy: 0.0863 - loss: 2.7397 - val_accuracy: 0.2611 - val_loss: 2.2476\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.2849 - loss: 2.1044 - val_accuracy: 0.4222 - val_loss: 1.6817\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.4624 - loss: 1.5026 - val_accuracy: 0.5889 - val_loss: 1.2032\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.5655 - loss: 1.2843 - val_accuracy: 0.6667 - val_loss: 1.0559\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - accuracy: 0.6561 - loss: 1.1034 - val_accuracy: 0.5389 - val_loss: 1.2588\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.6715 - loss: 0.9737 - val_accuracy: 0.7222 - val_loss: 0.8662\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 195ms/step - accuracy: 0.6637 - loss: 1.0118 - val_accuracy: 0.6889 - val_loss: 0.9155\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.7033 - loss: 0.9505 - val_accuracy: 0.7056 - val_loss: 0.8854\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.7674 - loss: 0.7301 - val_accuracy: 0.6944 - val_loss: 0.8507\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.7252 - loss: 0.8114 - val_accuracy: 0.7278 - val_loss: 0.8478\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.7385 - loss: 0.7913 - val_accuracy: 0.6889 - val_loss: 0.8722\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.7387 - loss: 0.7506 - val_accuracy: 0.7556 - val_loss: 0.7251\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - accuracy: 0.7967 - loss: 0.6237 - val_accuracy: 0.7500 - val_loss: 0.6594\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.7695 - loss: 0.6448 - val_accuracy: 0.7222 - val_loss: 0.7826\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.7893 - loss: 0.6042 - val_accuracy: 0.7889 - val_loss: 0.7195\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.7894 - loss: 0.5901 - val_accuracy: 0.7778 - val_loss: 0.6801\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - accuracy: 0.8375 - loss: 0.4863 - val_accuracy: 0.7778 - val_loss: 0.6855\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - accuracy: 0.8417 - loss: 0.4580 - val_accuracy: 0.7389 - val_loss: 0.8703\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.8249 - loss: 0.4983 - val_accuracy: 0.6278 - val_loss: 1.0847\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.7616 - loss: 0.6199 - val_accuracy: 0.5833 - val_loss: 1.5059\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - accuracy: 0.8300 - loss: 0.5208 - val_accuracy: 0.7722 - val_loss: 0.6591\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.8574 - loss: 0.4334 - val_accuracy: 0.7222 - val_loss: 0.8805\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - accuracy: 0.8805 - loss: 0.3959 - val_accuracy: 0.7833 - val_loss: 0.6701\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - accuracy: 0.8630 - loss: 0.3729 - val_accuracy: 0.7611 - val_loss: 0.9090\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.8134 - loss: 0.4868 - val_accuracy: 0.7833 - val_loss: 0.7724\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.8397 - loss: 0.4802 - val_accuracy: 0.7889 - val_loss: 0.5198\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.8491 - loss: 0.4127 - val_accuracy: 0.7667 - val_loss: 0.8148\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 213ms/step - accuracy: 0.8849 - loss: 0.3475 - val_accuracy: 0.7722 - val_loss: 0.7129\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.8494 - loss: 0.4464 - val_accuracy: 0.8000 - val_loss: 0.6368\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 197ms/step - accuracy: 0.8725 - loss: 0.3237 - val_accuracy: 0.7889 - val_loss: 0.6990\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.8912 - loss: 0.2951 - val_accuracy: 0.7778 - val_loss: 1.0262\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - accuracy: 0.9047 - loss: 0.2880 - val_accuracy: 0.8222 - val_loss: 0.5408\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - accuracy: 0.8755 - loss: 0.3465 - val_accuracy: 0.7889 - val_loss: 0.7849\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.8738 - loss: 0.3470 - val_accuracy: 0.7556 - val_loss: 0.8829\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.8612 - loss: 0.3952 - val_accuracy: 0.7944 - val_loss: 0.6795\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - accuracy: 0.8587 - loss: 0.4153 - val_accuracy: 0.7833 - val_loss: 0.7645\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.8971 - loss: 0.2566 - val_accuracy: 0.8278 - val_loss: 0.6059\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - accuracy: 0.8947 - loss: 0.2664 - val_accuracy: 0.8722 - val_loss: 0.4587\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.8981 - loss: 0.2957 - val_accuracy: 0.8111 - val_loss: 0.7640\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 195ms/step - accuracy: 0.8878 - loss: 0.2904 - val_accuracy: 0.8056 - val_loss: 0.7900\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.9028 - loss: 0.2495 - val_accuracy: 0.7722 - val_loss: 1.0345\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - accuracy: 0.9083 - loss: 0.2741 - val_accuracy: 0.8111 - val_loss: 0.6404\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.9420 - loss: 0.1964 - val_accuracy: 0.7944 - val_loss: 0.6886\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 206ms/step - accuracy: 0.8923 - loss: 0.2419 - val_accuracy: 0.8000 - val_loss: 0.5987\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.9270 - loss: 0.1911 - val_accuracy: 0.8444 - val_loss: 0.6594\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - accuracy: 0.9197 - loss: 0.2387 - val_accuracy: 0.8111 - val_loss: 0.7763\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - accuracy: 0.9264 - loss: 0.1950 - val_accuracy: 0.8722 - val_loss: 0.4687\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.8816 - loss: 0.3326 - val_accuracy: 0.7833 - val_loss: 0.8843\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.9233 - loss: 0.2290 - val_accuracy: 0.8167 - val_loss: 0.6389\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.9200 - loss: 0.2271 - val_accuracy: 0.8333 - val_loss: 0.5404\n",
      "Best epoch: 38\n"
     ]
    }
   ],
   "source": [
    "# Train to find best epoch\n",
    "\n",
    "history = model.fit(train_generator,epochs=50, validation_data=validation_generator)\n",
    "val_loss_per_epoch = history.history['val_loss']\n",
    "best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "print(f'Best epoch: {best_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 251ms/step - accuracy: 0.0918 - loss: 9.0773 - val_accuracy: 0.3111 - val_loss: 2.2661\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 218ms/step - accuracy: 0.2840 - loss: 2.2223 - val_accuracy: 0.4222 - val_loss: 1.5744\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.4773 - loss: 1.5294 - val_accuracy: 0.5778 - val_loss: 1.2043\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - accuracy: 0.5695 - loss: 1.2863 - val_accuracy: 0.5444 - val_loss: 1.5581\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.5997 - loss: 1.2350 - val_accuracy: 0.6389 - val_loss: 0.9783\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 188ms/step - accuracy: 0.7257 - loss: 0.8500 - val_accuracy: 0.5944 - val_loss: 1.1061\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 0.6975 - loss: 0.8935 - val_accuracy: 0.6833 - val_loss: 0.8599\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.6962 - loss: 0.8667 - val_accuracy: 0.7111 - val_loss: 0.8927\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 188ms/step - accuracy: 0.7099 - loss: 0.8471 - val_accuracy: 0.7111 - val_loss: 0.8005\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 185ms/step - accuracy: 0.8205 - loss: 0.6205 - val_accuracy: 0.7889 - val_loss: 0.6263\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.7675 - loss: 0.7018 - val_accuracy: 0.6944 - val_loss: 0.9565\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.7678 - loss: 0.6420 - val_accuracy: 0.7056 - val_loss: 0.8804\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.8121 - loss: 0.5204 - val_accuracy: 0.6889 - val_loss: 0.9471\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 213ms/step - accuracy: 0.7952 - loss: 0.6026 - val_accuracy: 0.7222 - val_loss: 0.7613\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.8339 - loss: 0.5085 - val_accuracy: 0.7667 - val_loss: 0.5163\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 189ms/step - accuracy: 0.8318 - loss: 0.4499 - val_accuracy: 0.6500 - val_loss: 1.1920\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 185ms/step - accuracy: 0.8169 - loss: 0.6062 - val_accuracy: 0.4944 - val_loss: 1.9379\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 188ms/step - accuracy: 0.8076 - loss: 0.6910 - val_accuracy: 0.7833 - val_loss: 0.5997\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 0.8349 - loss: 0.4950 - val_accuracy: 0.7889 - val_loss: 0.5924\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.8637 - loss: 0.3709 - val_accuracy: 0.8056 - val_loss: 0.5214\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - accuracy: 0.8812 - loss: 0.3853 - val_accuracy: 0.7222 - val_loss: 0.6310\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 181ms/step - accuracy: 0.8593 - loss: 0.4184 - val_accuracy: 0.7500 - val_loss: 0.7727\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.8607 - loss: 0.4024 - val_accuracy: 0.8389 - val_loss: 0.5339\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - accuracy: 0.8555 - loss: 0.3904 - val_accuracy: 0.8000 - val_loss: 0.5591\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 181ms/step - accuracy: 0.8808 - loss: 0.3218 - val_accuracy: 0.8111 - val_loss: 0.5081\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 188ms/step - accuracy: 0.8757 - loss: 0.3406 - val_accuracy: 0.7833 - val_loss: 0.6925\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 187ms/step - accuracy: 0.9105 - loss: 0.2713 - val_accuracy: 0.7889 - val_loss: 0.6872\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 197ms/step - accuracy: 0.9016 - loss: 0.2828 - val_accuracy: 0.7722 - val_loss: 0.9981\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 185ms/step - accuracy: 0.8735 - loss: 0.3200 - val_accuracy: 0.8167 - val_loss: 0.5961\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - accuracy: 0.8745 - loss: 0.3191 - val_accuracy: 0.7833 - val_loss: 0.7585\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.9126 - loss: 0.2910 - val_accuracy: 0.7389 - val_loss: 0.7836\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step - accuracy: 0.8938 - loss: 0.3054 - val_accuracy: 0.8056 - val_loss: 0.6570\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.8917 - loss: 0.3008 - val_accuracy: 0.7889 - val_loss: 0.7958\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.9144 - loss: 0.2474 - val_accuracy: 0.7889 - val_loss: 0.7562\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 195ms/step - accuracy: 0.8838 - loss: 0.3229 - val_accuracy: 0.7722 - val_loss: 0.7253\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 182ms/step - accuracy: 0.8898 - loss: 0.2757 - val_accuracy: 0.8056 - val_loss: 0.7315\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 195ms/step - accuracy: 0.9095 - loss: 0.2405 - val_accuracy: 0.8111 - val_loss: 0.6440\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 200ms/step - accuracy: 0.9119 - loss: 0.2337 - val_accuracy: 0.8111 - val_loss: 0.6721\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 186ms/step - accuracy: 0.9271 - loss: 0.1904 - val_accuracy: 0.7889 - val_loss: 0.7634\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 182ms/step - accuracy: 0.9206 - loss: 0.2206 - val_accuracy: 0.7778 - val_loss: 1.0416\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 188ms/step - accuracy: 0.8774 - loss: 0.3269 - val_accuracy: 0.8778 - val_loss: 0.3667\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 0.9266 - loss: 0.2352 - val_accuracy: 0.8167 - val_loss: 0.6525\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.9239 - loss: 0.2451 - val_accuracy: 0.8333 - val_loss: 0.4879\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - accuracy: 0.9162 - loss: 0.2519 - val_accuracy: 0.7333 - val_loss: 1.3155\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.9030 - loss: 0.2486 - val_accuracy: 0.7833 - val_loss: 0.7564\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.9448 - loss: 0.1474 - val_accuracy: 0.8000 - val_loss: 0.7257\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.9342 - loss: 0.1680 - val_accuracy: 0.8222 - val_loss: 0.6065\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 232ms/step - accuracy: 0.9529 - loss: 0.1460 - val_accuracy: 0.8722 - val_loss: 0.4337\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 231ms/step - accuracy: 0.9343 - loss: 0.1744 - val_accuracy: 0.7444 - val_loss: 1.0205\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 213ms/step - accuracy: 0.9360 - loss: 0.1974 - val_accuracy: 0.8278 - val_loss: 0.6603\n",
      "Best epoch: 41\n"
     ]
    }
   ],
   "source": [
    "history_rs = model_rs.fit(train_generator,epochs=50, validation_data=validation_generator)\n",
    "val_loss_per_epoch_rs = history_rs.history['val_loss']\n",
    "best_epoch_rs = val_loss_per_epoch_rs.index(min(val_loss_per_epoch_rs)) + 1\n",
    "print(f'Best epoch: {best_epoch_rs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 268ms/step - accuracy: 0.0436 - loss: 2.7122 - val_accuracy: 0.1167 - val_loss: 2.6685\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 195ms/step - accuracy: 0.1112 - loss: 2.5932 - val_accuracy: 0.2833 - val_loss: 2.0825\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 200ms/step - accuracy: 0.2546 - loss: 2.0774 - val_accuracy: 0.3944 - val_loss: 1.7432\n",
      "Epoch 4/50\n"
     ]
    }
   ],
   "source": [
    "history_bo = model_bo.fit(train_generator,epochs=50, validation_data=validation_generator)\n",
    "val_loss_per_epoch_bo = history_bo.history['val_loss']\n",
    "best_epoch_bo = val_loss_per_epoch_bo.index(min(val_loss_per_epoch_bo)) + 1\n",
    "print(f'Best epoch: {best_epoch_bo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "hypermodel_rs = tuner_rs.hypermodel.build(best_hps_rs)\n",
    "hypermodel_bo = tuner_rs.hypermodel.build(best_hps_bo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model\n",
    "history = hypermodel.fit(train_generator, epochs=best_epoch, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_rs = hypermodel_rs.fit(train_generator, epochs=best_epoch_rs, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_bo = hypermodel_bo.fit(train_generator, epochs=best_epoch_bo, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel.summary()\n",
    "hypermodel_rs.summary()\n",
    "hypermodel_bo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel.save('hypermodel_basic.keras')\n",
    "hypermodel_rs.save('hypermodel_rs.keras')\n",
    "hypermodel_bo.save('hypermodel_bo.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_img_file = 'hypermodel.png'\n",
    "# tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Hyperband model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Hyperband model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_rs.history['accuracy'])\n",
    "plt.plot(history_rs.history['val_accuracy'])\n",
    "plt.title('RandomSearch model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_rs.history['loss'])\n",
    "plt.plot(history_rs.history['val_loss'])\n",
    "plt.title('RandomSearch model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_bo.history['accuracy'])\n",
    "plt.plot(history_bo.history['val_accuracy'])\n",
    "plt.title('Bayesian Optimization model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_bo.history['loss'])\n",
    "plt.plot(history_bo.history['val_loss'])\n",
    "plt.title('Bayesian Optimization model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history = hypermodel.evaluate(test_generator)\n",
    "test_history_rs = hypermodel_rs.evaluate(test_generator)\n",
    "test_history_bo = hypermodel_bo.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"For model with Hyperband tuning, testing loss is {test_history[0]} and accuracy is {test_history[1]}\")\n",
    "print(f\"For model with Random Search tuning, testing loss is {test_history_rs[0]} and accuracy is {test_history_rs[1]}\")\n",
    "print(f\"For model with Bayesian Optimization tuning, testing loss is {test_history_bo[0]} and accuracy is {test_history_bo[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
